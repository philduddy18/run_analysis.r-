# CODE BOOK for the 'tidy_data_summary' data table. 
 *** 
 *** 

 ## Table of Contents 
 *** 

 The code book consists of the following: 

   0. Table of Contents 
   1. Informations on 'tidy_data_summary' data table 
      - Identificators and averages of features 
      - Description for the variables of 'tidy_data_summary' 
      - How to load 'tidy_data_summary' in R
      - About 'tidy_data_summary' table 
   2. The process by which the 'tidy_data_summary' table was produced 
   3. Description of the features on which the averages were based 
      - Informations on how the features were produced from the raw data 
      - Informations on the collection of raw data 
      - About the original data set 
   4. License 


 *** 
 ## Informations on 'tidy_data_summary' data table 
 *** 

 ### Identificators and averages of features

 The first 2 variables, 'subject' and 'activity',
 can uniquely identify each row of the table. 
 The rest 66 variables, are the averages for some selected features,
 those which contain informations on means and standard deviations,
 from the original dataset:
 'Human Activity Recognition Using Smartphones Dataset Version 1.0'.


 ### Description of the variables from 'tidy_data_summary'

 The following table describes all variables of the 'tidy_data_summary' table. 

 | Index |           Variables          |  Class  |  Range  | Description                                                                                               |
 |-------|------------------------------| --------|---------|-----------------------------------------------------------------------------------------------------------|
 |    1  | subject                      | integer |  1 - 30 | Identifies the human subject.                                                                             |
 |    2  | activity                     | factor  |  1 -  6 | Identifies the activity. Labels: WALKING, WALKING UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING |
 |    3  | Avrg-tBodyAcc-mean()-X       | numeric | [-1, 1] | Time domain, Average of means for body acceleration on X axis.                                            |
 |    4  | Avrg-tBodyAcc-mean()-Y       | numeric | [-1, 1] | Time domain, Average of means for body acceleration on Y axis.                                            |
 |    5  | Avrg-tBodyAcc-mean()-Z       | numeric | [-1, 1] | Time domain, Average of means for body acceleration on Z axis.                                            |
 |    6  | Avrg-tBodyAcc-std()-X        | numeric | [-1, 1] | Time domain, Average of standard deviations for body acceleration on X axis.                              |
 |    7  | Avrg-tBodyAcc-std()-Y        | numeric | [-1, 1] | Time domain, Average of standard deviations for body acceleration on Y axis.                              |
 |    8  | Avrg-tBodyAcc-std()-Z        | numeric | [-1, 1] | Time domain, Average of standard deviations for body acceleration on Z axis.                              |
 |    9  | Avrg-tGravityAcc-mean()-X    | numeric | [-1, 1] | Time domain, Average of means for gravity acceleration on X axis.                                         |
 |   10  | Avrg-tGravityAcc-mean()-Y    | numeric | [-1, 1] | Time domain, Average of means for gravity acceleration on Y axis.                                         |
 |   11  | Avrg-tGravityAcc-mean()-Z    | numeric | [-1, 1] | Time domain, Average of means for gravity acceleration on Z axis.                                         |
 |   12  | Avrg-tGravityAcc-std()-X     | numeric | [-1, 1] | Time domain, Average of standard deviations for gravity acceleration on X axis.                           |
 |   13  | Avrg-tGravityAcc-std()-Y     | numeric | [-1, 1] | Time domain, Average of standard deviations for gravity acceleration on Y axis.                           |
 |   14  | Avrg-tGravityAcc-std()-Z     | numeric | [-1, 1] | Time domain, Average of standard deviations for gravity acceleration on Z axis.                           |
 |   15  | Avrg-tBodyAccJerk-mean()-X   | numeric | [-1, 1] | Time domain, Average of means for the jerk of body acceleration on X axis.                                |
 |   16  | Avrg-tBodyAccJerk-mean()-Y   | numeric | [-1, 1] | Time domain, Average of means for the jerk of body acceleration on Y axis.                                |
 |   17  | Avrg-tBodyAccJerk-mean()-Z   | numeric | [-1, 1] | Time domain, Average of means for the jerk of body acceleration on Z axis.                                |
 |   18  | Avrg-tBodyAccJerk-std()-X    | numeric | [-1, 1] | Time domain, Average of standard deviations for the jerk of body acceleration on X axis.                  |
 |   19  | Avrg-tBodyAccJerk-std()-Y    | numeric | [-1, 1] | Time domain, Average of standard deviations for the jerk of body acceleration on Y axis.                  |
 |   20  | Avrg-tBodyAccJerk-std()-Z    | numeric | [-1, 1] | Time domain, Average of standard deviations for the jerk of body acceleration on Z axis.                  |
 |   21  | Avrg-tBodyGyro-mean()-X      | numeric | [-1, 1] | Time domain, Average of means for angular velocity on X axis.                                             |
 |   22  | Avrg-tBodyGyro-mean()-Y      | numeric | [-1, 1] | Time domain, Average of means for angular velocity on Y axis.                                             |
 |   23  | Avrg-tBodyGyro-mean()-Z      | numeric | [-1, 1] | Time domain, Average of means for angular velocity on Z axis.                                             |
 |   24  | Avrg-tBodyGyro-std()-X       | numeric | [-1, 1] | Time domain, Average of standard deviations for angular velocity on X axis.                               |
 |   25  | Avrg-tBodyGyro-std()-Y       | numeric | [-1, 1] | Time domain, Average of standard deviations for angular velocity on Y axis.                               |
 |   26  | Avrg-tBodyGyro-std()-Z       | numeric | [-1, 1] | Time domain, Average of standard deviations for angular velocity on Z axis.                               |
 |   27  | Avrg-tBodyGyroJerk-mean()-X  | numeric | [-1, 1] | Time domain, Average of means for the jerk of angular velocity on X axis.                                 |
 |   28  | Avrg-tBodyGyroJerk-mean()-Y  | numeric | [-1, 1] | Time domain, Average of means for the jerk of angular velocity on Y axis.                                 |
 |   29  | Avrg-tBodyGyroJerk-mean()-Z  | numeric | [-1, 1] | Time domain, Average of means for the jerk of angular velocity on Z axis.                                 |
 |   30  | Avrg-tBodyGyroJerk-std()-X   | numeric | [-1, 1] | Time domain, Average of standard deviations for the jerk of angular velocity on X axis.                   |
 |   31  | Avrg-tBodyGyroJerk-std()-Y   | numeric | [-1, 1] | Time domain, Average of standard deviations for the jerk of angular velocity on Y axis.                   |
 |   32  | Avrg-tBodyGyroJerk-std()-Z   | numeric | [-1, 1] | Time domain, Average of standard deviations for the jerk of angular velocity on Z axis.                   |
 |   33  | Avrg-tBodyAccMag-mean()      | numeric | [-1, 1] | Time domain, Average of means for the magnitude of body acceleration.                                     |
 |   34  | Avrg-tBodyAccMag-std()       | numeric | [-1, 1] | Time domain, Average of standard deviations for the magnitude of body acceleration.                       |
 |   35  | Avrg-tGravityAccMag-mean()   | numeric | [-1, 1] | Time domain, Average of means for the magnitude of gravity acceleration.                                  |
 |   36  | Avrg-tGravityAccMag-std()    | numeric | [-1, 1] | Time domain, Average of standard deviations for the magnitude of gravity acceleration.                    |
 |   38  | Avrg-tBodyAccJerkMag-mean()  | numeric | [-1, 1] | Time domain, Average of means for the magnitude of jerk, of body accelaration.                            |
 |   38  | Avrg-tBodyAccJerkMag-std()   | numeric | [-1, 1] | Time domain, Average of standard deviations for the magnitude of jerk, of body accelaration.              |
 |   39  | Avrg-tBodyGyroMag-mean()     | numeric | [-1, 1] | Time domain, Average of means for the magnitude of angular velocity.                                      |
 |   40  | Avrg-tBodyGyroMag-std()      | numeric | [-1, 1] | Time domain, Average of standard deviations for the magnitude of angular velocity.                        |
 |   41  | Avrg-tBodyGyroJerkMag-mean() | numeric | [-1, 1] | Time domain, Average of means for the magnitude of jerk, of the angular velocity.                         |
 |   42  | Avrg-tBodyGyroJerkMag-std()  | numeric | [-1, 1] | Time domain, Average of standard deviations for the magnitude of jerk, of the angular velocity.           |
 |   43  | Avrg-fBodyAcc-mean()-X       | numeric | [-1, 1] | Frequency domain, Average of means for body acceleration on X axis.                                       |
 |   44  | Avrg-fBodyAcc-mean()-Y       | numeric | [-1, 1] | Frequency domain, Average of means for body acceleration on Y axis.                                       |
 |   45  | Avrg-fBodyAcc-mean()-Z       | numeric | [-1, 1] | Frequency domain, Average of means for body acceleration on Z axis.                                       |
 |   46  | Avrg-fBodyAcc-std()-X        | numeric | [-1, 1] | Frequency domain, Average of standard deviations for body acceleration on X axis.                         |
 |   47  | Avrg-fBodyAcc-std()-Y        | numeric | [-1, 1] | Frequency domain, Average of standard deviations for body acceleration on Y axis.                         |
 |   48  | Avrg-fBodyAcc-std()-Z        | numeric | [-1, 1] | Frequency domain, Average of standard deviations for body acceleration on Z axis.                         |
 |   49  | Avrg-fBodyAccJerk-mean()-X   | numeric | [-1, 1] | Frequency domain, Average of means for the jerk of the body acceleration on X axis.                       |
 |   50  | Avrg-fBodyAccJerk-mean()-Y   | numeric | [-1, 1] | Frequency domain, Average of means for the jerk of the body acceleration on Y axis.                       |
 |   51  | Avrg-fBodyAccJerk-mean()-Z   | numeric | [-1, 1] | Frequency domain, Average of means for the jerk of the body acceleration on Z axis.                       |
 |   52  | Avrg-fBodyAccJerk-std()-X    | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the jerk of the body acceleration on X axis.         |
 |   53  | Avrg-fBodyAccJerk-std()-Y    | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the jerk of the body acceleration on Y axis.         |
 |   54  | Avrg-fBodyAccJerk-std()-Z    | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the jerk of the body acceleration on Z axis.         |
 |   55  | Avrg-fBodyGyro-mean()-X      | numeric | [-1, 1] | Frequency domain, Average of means for the jerk of angular velocity on X axis.                            |
 |   56  | Avrg-fBodyGyro-mean()-Y      | numeric | [-1, 1] | Frequency domain, Average of means for the jerk of angular velocity on Y axis.                            |
 |   57  | Avrg-fBodyGyro-mean()-Z      | numeric | [-1, 1] | Frequency domain, Average of means for the jerk of angular velocity on Z axis.                            |
 |   58  | Avrg-fBodyGyro-std()-X       | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the jerk of angular velocity on X axis.              |
 |   59  | Avrg-fBodyGyro-std()-Y       | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the jerk of angular velocity on Y axis.              |
 |   60  | Avrg-fBodyGyro-std()-Z       | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the jerk of angular velocity on Z axis.              |
 |   61  | Avrg-fBodyAccMag-mean()      | numeric | [-1, 1] | Frequency domain, Average of means for the magnitude of body acceleration.                                |
 |   62  | Avrg-fBodyAccMag-std()       | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the magnitude of body acceleration.                  |
 |   63  | Avrg-fBodyAccJerkMag-mean()  | numeric | [-1, 1] | Frequency domain, Average of means for the magnitude of jerk, of body acceleration.                       |
 |   64  | Avrg-fBodyAccJerkMag-std()   | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the magnitude of jerk, of body acceleration.         |
 |   65  | Avrg-fBodyGyroMag-mean()     | numeric | [-1, 1] | Frequency domain, Average of means for the magnitude of angular velocity.                                 |
 |   66  | Avrg-fBodyGyroMag-std()      | numeric | [-1, 1] | Frequency domain, Average of standard deviations for the magnitude of angular velocity.                   |
 |   67  | Avrg-fBodyGyroJerkMag-mean() | numeric | [-1, 1] | Frequency domain, Average of means for the magnitude of jerk, of angular velocity.                        |
 |   68  | Avrg-fBodyGyroJerkMag-std()  | numeric | [-1, 1] | Frequency domain, Average of standard deviation for the magnitude of jerk, of angular velocity.           |


 ### How to load 'tidy_data_summary' data in R 

 It order to load the 'tidy_data_summary' in R correctly,
 use the following command:

 ``` 
 tidy_data_summary <- read.table(file = "tidy_data_summary.txt",
                                 header = TRUE, check.names = FALSE, dec = ".") 
 ``` 

 Or for faster loading some additional arguments can be specified: 

 ```   
 tidy_data_summary <- read.table(file  = "tidy_data_summary.txt", 
                                 header = TRUE, check.names = FALSE, dec = ".", 
                                 colClasses = c("numeric", "factor", "rep("numeric", 66)), 
                                 nrows = 180, comments.char = "", quote = "") 
 ``` 

 ### About 'tidy_data_summary' table 

 This dataset was created for the needs of: 

 > Course 3: 'Getting and Cleaning Data', 
 > from 'Data Science Specialization', 
 > by 'Johns Hopkins University', 
 > on Coursera 
 >
 > The course is taught by: 
 >
 >    - Jeff Leek, Phd 
 >    - Roger D. Peng, Phd 
 >    - Brian Caffo, Phd 
  
 The data table can be reproduced,
 as all required scripts are available on the Git Hub repository
 [Getting and Cleaning Data Assignment](). 
 Before trying to reproduce it,
 the following notes should be taken into account:
  
   - The data used for the download was accessed by the script
     '[get_project_data.R]()', from the url:
     "http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones"
     at 'Sat Jan 27 14:59:09 2018'.
   - The data was then processed by the script '[run_analysis.R]()'
     to create the 'tidy_data_summary' table.
   - The scripts were executed in RStudio (version 1.1.383)
   - The library 'dplyr' version 0.7.4 was used.
   - The output produced by 'R.version' is the following following:
  
 ```
 platform       x86_64-pc-linux-gnu        
 arch           x86_64                     
 os             linux-gnu                  
 system         x86_64, linux-gnu          
 status                                    
 major          3                          
 minor          4.3                        
 year           2017                       
 month          11                         
 day            30                         
 svn rev        73796                      
 language       R                          
 version.string R version 3.4.3 (2017-11-30)
 nickname       Kite-Eating Tree 

 ``` 
   
 *** 
 ## The process by which the 'tidy_data_summary' table was produced  
 *** 

 In order to produce the 'tidy_data_summary' table,
 the script '[run_analysis.R](https://....)' was created and used. 
 It performs the following tasks: 

 #### Merges the training and the test sets to create one data set with target variables. 

   1. Binds these files,
        - UCI HAR Dataset/train/subject_train.txt
        - UCI HAR Dataset/train/X_train.txt
        - UCI HAR Dataset/train/y_train.txt.

      from the train set by columns to a table that contains,
      the human subject, the activity performed and the values of the features. 
   2. Binds these files,
        - UCI HAR Dataset/test/subject_test.txt
        - UCI HAR Dataset/test/X_test.txt
        - UCI HAR Dataset/test/y_test.txt.

      from the test set by columns to a table that contains,
      the human subject, the activity performed and the values of the features. 
   3. Binds the data frames created for test and train set into one large dataset
      by rows.

 #### Extracts only the measurements on the mean and standard deviation for each measurement. 

   1. Finds the target features, which are the features with measurements
      about mean and standard deviation, and extracts them as well as those
      that indicate the 'subject' and 'activity' and creates a new data table
      only with the target variables. 

 #### Uses descriptive activity names to name the activities in the data set.   

   1. Replace the variable about activity, that contains integers from 1 to 6,
      with a factor based on levels and labels contained in the 'activity_labels'
      data file. 

 #### Appropriately labels the data set with target variables with descriptive names. 

   1. Extracts the target variable names from 'features.txt'.
   2. Corrects a typo that exists in some feature names, that is to replace
      'BodyBody' that appears in the names of some features with just 'Body'.
   3. Creates a new tidy dataset with the appropriate labels for the variable
      names. 

 #### From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject. 


   1. Group the tidy data table created in step 4, by 'subject' and 'activity'. 
   2. Summarize each variable to find the average for the grouped values. 
   3. Ungroup the data table. 
   4. Add descriptive names to the variables of the new tidy data table,
      by adding the prefix 'Avrg-' in the names of the target feature averages.
   5. Write the data in a text file in the present working directory,
      by the command: 

      ```
      write.table(tidy_data_summary, "tidy_data_summary.txt", row.names = FALSE) 
      ```

 ***
 ## Description of the features on which the averages were based 
 *** 

 ### Informations on how the features were produced from the raw data 

 The selected features were produced, as it is explained in the
 'features_info.txt' file of the original data set:

 > The features selected for this database come from the accelerometer and
 gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals
 (prefix 't' to denote time) were captured at a constant rate of 50 Hz.
 Then they were filtered using a median filter and a 3rd order low pass
 Butterworth filter with a corner frequency of 20 Hz to remove noise.
 Similarly, the acceleration signal was then separated into body and gravity
 acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass
 Butterworth filter with a corner frequency of 0.3 Hz.
 >
 > Subsequently, the body linear acceleration and angular velocity were derived
 in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ).
 Also the magnitude of these three-dimensional signals were calculated using
 the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag,
 tBodyGyroJerkMag).
 >
 > Finally a Fast Fourier Transform (FFT) was applied to some of these signals
 producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag,
 fBodyGyroMag, fBodyGyroJerkMag.
 (Note the 'f' to indicate frequency domain signals).
 >
 >These signals were used to estimate variables of the feature vector
 for each pattern: 
 '-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.
 >
 > tBodyAcc-XYZ 
 > tGravityAcc-XYZ 
 > tBodyAccJerk-XYZ 
 > tBodyGyro-XYZ 
 > tBodyGyroJerk-XYZ 
 > tBodyAccMag 
 > tGravityAccMag 
 > tBodyAccJerkMag 
 > tBodyGyroMag 
 > tBodyGyroJerkMag 
 > fBodyAcc-XYZ 
 > fBodyAccJerk-XYZ 
 > fBodyGyro-XYZ 
 > fBodyAccMag 
 > fBodyAccJerkMag 
 > fBodyGyroMag 
 > fBodyGyroJerkMag 
 >
 > The set of variables that were estimated from these signals are: 
 >
 > mean(): Mean value 
 > std(): Standard deviation 
 > mad(): Median absolute deviation 
 > max(): Largest value in array 
 > min(): Smallest value in array 
 > sma(): Signal magnitude area 
 > energy(): Energy measure. Sum of the squares divided by the number of values. 
 > iqr(): Interquartile range 
 > entropy(): Signal entropy 
 > arCoeff(): Autorregresion coefficients with Burg order equal to 4 
 > correlation(): correlation coefficient between two signals 
 > maxInds(): index of the frequency component with largest magnitude 
 > meanFreq(): Weighted average of the frequency components to obtain a mean
 frequency 
 > skewness(): skewness of the frequency domain signal  
 > kurtosis(): kurtosis of the frequency domain signal  
 > bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT
 of each window. 
 > angle(): Angle between to vectors. 
 > 
 > Additional vectors obtained by averaging the signals in a signal window
 sample. These are used on the angle() variable: 
 > 
 > gravityMean 
 > tBodyAccMean 
 > tBodyAccJerkMean 
 > tBodyGyroMean 
 > tBodyGyroJerkMean 
 > 

 ### Informations on the collection of raw data 

 The raw singals were produced, as it is explained in the 'README.txt' file of
 original data set:

 > The experiments have been carried out with a group of 30 volunteers within
 an age bracket of 19-48 years. Each person performed six activities
 (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
 wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded
 accelerometer and gyroscope, we captured 3-axial linear acceleration and
 3-axial angular velocity at a constant rate of 50Hz. The experiments have been
 video-recorded to label the data manually. The obtained dataset has been
 randomly partitioned into two sets, where 70% of the volunteers was selected
 for generating the training data and 30% the test data. 
 >
 >The sensor signals (accelerometer and gyroscope) were pre-processed by
 applying noise filters and then sampled in fixed-width sliding windows of
 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal,
 which has gravitational and body motion components, was separated using
 a Butterworth low-pass filter into body acceleration and gravity.
 The gravitational force is assumed to have only low frequency components,
 therefore a filter with 0.3 Hz cutoff frequency was used. From each window,
 a vector of features was obtained by calculating variables from the time and
 frequency domain. See 'features_info.txt' for more details. 
 > 
 > #### For each record it is provided: 
 > 
 > - Triaxial acceleration from the accelerometer (total acceleration)
 and the estimated body acceleration. 
 > - Triaxial Angular velocity from the gyroscope. 
 > - A 561-feature vector with time and frequency domain variables. 
 > - Its activity label. 
 > - An identifier of the subject who carried out the experiment. 
  
 and also it include the following notes: 

 > Notes: 
 > 
 > - Features are normalized and bounded within [-1,1]. 
 > - Each feature vector is a row on the text file. 
  

 ### About the original dataset 

 The 'tidy_data_summary' table was created by using the following data set: 
 (the following is copy-paste from the data set's 'README.txt') 

 > ================================================================== 
 > Human Activity Recognition Using Smartphones Dataset 
 > Version 1.0 
 > ================================================================== 
 > Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto. 
 > Smartlab - Non Linear Complex Systems Laboratory 
 > DITEN - Universit? degli Studi di Genova. 
 > Via Opera Pia 11A, I-16145, Genoa, Italy. 
 > activityrecognition@smartlab.ws 
 > www.smartlab.ws 
 > ================================================================== 
  
 More informations about the original data set can be found
 [here](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).
  
  
 *** 
 ### License
 ***

 The following is a copy-paste from the 'README.txt' of the original data set
 which I encourage everybody to use.

 > Use of this dataset in publications must be acknowledged by referencing the
 following publication [1] 
 > 
 > [1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra
 and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a
 Multiclass Hardware-Friendly Support Vector Machine. International Workshop
 of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012 
 >
 > This dataset is distributed AS-IS and no responsibility implied or explicit
 can be addressed to the authors or their institutions for its use or misuse.
 Any commercial use is prohibited. 
 > 
 > Jorge L. Reyes-Ortiz, Alessandro Ghio, Luca Oneto, Davide Anguita.
 November 2012.
  
 ***




 93  get_project_data.R 

@@ -0,0 +1,93 @@
 ################################################################################
 # WHAT YOU SHOULD KNOW BEFORE EXECUTING THIS SCRIPT, 'get_project_data.R'
 ################################################################################

 # DESCRIPTION: This script downloads and extracts the 'UCI HAR Dataset'
 #              in the working directory if the folder doesn't exists.

 # DOWNLOAD URL:
 # "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"

 # PLAN:        Checks if the data files are available.
 #              If the data don't exist,
 #                  1. downloads the zipped file
 #                  2. creates a log file,
 #                     with the url used and the date of the download
 #                  3. extracts the zipped file
 #              else if the data files exist,
 #                  1. informs that the files already exist

 # NOTES:       When 'get_project_data.R' is executed,
 #              informative messages are printed in console,
 #              to describe what the script tries to do.




 ################################################################################
 # Downloads and unzips the 'UCI HAR Dataset'
 ################################################################################

 ## Checks if the folder 'UCI HAR Dataset' (this is the default name) exists
 ## in the working directory.
 ##     * if the folder doesn't exists,
 ##           1. downloads the zipped files as 'data.zip',
 ##              in the working directory
 ##           2. creates a log to store the download url and date,
 ##              with name 'log.txt' in the working directory
 ##           3. extracts the zipped files in a folder with
 ##              the default name 'UCI HAR Dataset', in the working directory


 # Checks if the folder 'UCI HAR Dataset' already exists in the working directory
 message("Searching for folder 'UCI HAR Dataset' in the working directory...")

 if (!dir.exists("UCI HAR Dataset")) {
       # ONE EXTREME COINCIDENCE
       ## It does a simplistic test, yet sufficient on most of the cases,
       ## that is to check if a folder with name 'UCI HAR Dataset' exists
       ## in the working directory to determine if it should download the files.
       ## Obviously if you have, by luck or on purpose, a folder with that name,
       ## it will mistakenly assume that it contains the correct data files.
       message("    ...no folder with name 'UCI HAR Dataset'",
               " exists in the working directory.")


       # Downloads the needed zipped files
       message("Trying to download the zipped file...")
       data_url = paste0("https://d396qusza40orc.cloudfront.net/",
                         "getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip")
       download.file(data_url, "data.zip")
       message("    ...zipped data was downloaded successfully ",
               " in the working directory as 'data.zip'.")


       # Creates a log to to store
       # the url used for the download and the date when the download happened
       log_entry_url <- paste0("Data was downloaded from the url: ", data_url)
       log_entry_date <- paste0("Data was downloaded at date: " , date())

       log_con <- file("log.txt")
       writeLines(c(log_entry_url, log_entry_date), log_con)
       close(log_con)

       message("A file was created as 'log.txt' at the working directory \n",
               "which stores the url and the date, \n",
               "from which zipped data files where downloaded.")


       # Extracts files from zipped file 'data.zip'
       message("Trying to extract files from the 'data.zip'",
               "in the working directory...")
       unzip("data.zip")
       message("    ...data files extracted successfully, in the folder \n",
               "       with name 'UCI HAR Dataset' in the working directory.")


 } else {
       message("    ...data files are available, in the folder \n",
               "       with name 'UCI HAR Dataset' in the working directory.")
 }

 # THE END ######################################################################

 301  run_analysis.R 

@@ -0,0 +1,301 @@
 ################################################################################
 # WHAT YOU NEED TO KNOW BEFORE EXECUTING THIS SCRIPT
 ################################################################################
 # IMPORTANT: This script, 'run_analysis.R', works under one requirement:
 #                 A folder with name 'UCI HAR Dataset' ,
 #                 is present in the working directory
 #                 that contains the following data files:
 #                   - UCI HAR Dataset/activity_labels.txt
 #                   - UCI HAR Dataset/features.txt
 #                   - UCI HAR Dataset/test/subject_test.txt
 #                   - UCI HAR Dataset/test/X_test.txt
 #                   - UCI HAR Dataset/test/y_test.txt
 #                   - UCI HAR Dataset/train/subject_train.txt
 #                   - UCI HAR Dataset/train/X_train.txt
 #                   - UCI HAR Dataset/train/y_train.txt
 #                 from 'Human Activity Recognition Using
 #                       Smartphones Dataset Version 1.0'
 #                 which can be downloaded from the following url:
 #                 "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
 #
 #            TIP   
 #            The script 'get_project_data.R' was created and used,
 #            to download and extract the needed files for 'run_analysis.R'.
 #            It is recommended to use it, but not necessary.
 #            It is available on Git Hub, through this link:
 #            "https://...."
 #
 #            ABOUT
 #            The script was created:
 #               - in RStudio Version 1.1.383
 #               - with R version 3.4.3
 #               - and used dplyr_0.7.4
 #               - data was downloaded at date:

 # DESCRIPTION: The script 'run_analysis.R' follows strictly the instruction
 #              given by assignment, in a simple straightforward way.
 #                 0. Loads the data in R.
 #              Then 5 main steps are executed in order.
 #                 1. Merges the training and the test sets
 #                    to create one data set.
 #                 2. Extracts only the measurements on the mean
 #                    and standard deviation for each measurement.
 #                 3. Uses descriptive activity names
 #                    to name the activities in the data set.
 #                 4. Appropriately labels the data set
 #                    with descriptive variable names.
 #                 5. From the data set in step 4,
 #                    creates a second, independent tidy data set
 #                    with the average of each variable
 #                    for each activity and each subject.

 # RESULT:   The result is to create the 'tidy_data_summary' data table
 #           with the average values for the target features,
 #           which is saved as 'tidy_data_summary.txt' in the working directory.
 #          
 #           The resulting data table, can be loaded in R,
 #           with correct variable names, classes and values by the command:
 #
 #           tidy_data_summary <- read.table(file = "tidy_data_summary.txt",
 #                                           header = TRUE, check.names = FALSE,
 #                                           dec = ".") 
 #
 #           or for faster loading:
 #
 #           tidy_data_summary <- read.table(file  = "tidy_data_summary.txt",
 #                                           header = TRUE, check.names = FALSE,
 #                                           dec = ".",
 #                                           colClasses = c("numeric", "factor",
 #                                                          "rep("numeric", 66)),
 #                                           nrows = 180,
 #                                           comments.char = "", quote = "") 
 #          
 #           Details on the 'tidy_data_summary' table can be found,
 #           at 'CodeBook.md' that exist in the Git Hub, from the link:
 #           "https://...
 #




 ################################################################################
 # Loads required libraries
 ################################################################################
 # Version: dplyr_0_7_4.
 library(dplyr)




 ################################################################################
 # STEP 0: Loads all the data files needed for this analysis in R
 ################################################################################

 ## Plan: 1. Create a list with instructions for read.table(),
 ##          that contains the correct arguments for each file,
 ##          to be supplied through 'Map()'.
 ##          The list contains the values for the arguments of 'read.table()':
 ##              - 'file'
 ##              - 'colClasses'
 ##              - 'nrows'
 ##          for each file we want to load.
 ##       2. Use 'Map()' to load each files with function 'read.table()',
 ##          based on the instructions supplied for each file's arguments
 ##          in the 'read.table_instructions' list
 ##          as well as some extra, common arguments for all files.

 ## Some thoughts about the plan:
 ##    The use of Map() is not necessary when a small number of files is needed,
 ##    like in this analysis, where it is not obvious if it really saves space..
 ##    However when a lot of files have to be treated in a similar way
 ##    it should always be used, not only to save time and effort,
 ##    but also to avoid one source of common errors in coding,
 ##    which is the programmer who writes the same commands many times.
 ##    According to the 'D.R.Y' principle: "Don't Repeat Yourself"


 message("Trying to load data files in R...")

 ## Creates the list with the instructions needed by 'read.table()'
 read.table_instructions <- list(
       # The first object is a list with name 'file'
       # that contains values for 'file' argument,
       # which indicates the path of each file.
       file = list(
             activity_labels = "UCI HAR Dataset/activity_labels.txt",
             features = "UCI HAR Dataset/features.txt",
             subject_train = "UCI HAR Dataset/train/subject_train.txt",
             y_train = "UCI HAR Dataset/train/y_train.txt",
             X_train = "UCI HAR Dataset/train/X_train.txt",
             subject_test = "UCI HAR Dataset/test/subject_test.txt",
             y_test = "UCI HAR Dataset/test/y_test.txt",
             X_test = "UCI HAR Dataset/test/X_test.txt"
       ),
       # The second object is a list with name 'colClasses'
       # that contains the values for 'colClasses' argument
       # that indicates the classes of all variables in each file.
       # It is supplied to correctly identify column classes,
       # and as side effect also improves reading speed.
       colClasses = list(
             activity_labels = c("integer", "character"),
             features = c("integer", "character"),
             subject_train = "integer",
             y_train = "integer",
             X_train = rep("numeric", 561),
             subject_test = "integer",
             y_test = "integer",
             X_test = rep("numeric", 561)
       ),
       # The third object is a list with name 'nrows'
       # that contains the values for 'nrows' argument
       # that indicates the number of rows to read in each file.
       # It is supplied for speed.
       nrows = list(
             activity_labels = 6,
             features = 561,
             subject_train = 2947,
             y_train = 2947,
             X_train = 2947,
             subject_test = 7352,
             y_test = 7352,
             X_test = 7352
       )
 )

 ## Uses the instructions created above to load all needed data with 'Map()'.
 ## For each file the correct arguments are supplied to function 'read.table()',
 ## as well as some extra, common arguments for all files.
 ## Function 'with()' is used for clearer code.
 data_files <- with(read.table_instructions,
                    Map(read.table,
                        file = file, colClasses = colClasses, nrows = nrows,
                        quote = "", comment.char = "",
                        stringsAsFactors = FALSE))

 message("    ...data files were successfully loaded into R, \n",
         "       in the list with name 'data_files'.")




 ################################################################################
 # STEP 1: Merges the training and the test sets to create one data set.
 ################################################################################

 ## Plan: 1. Bind the files of the train set together by columns.
 ##       2. Bind the files of the test set together by columns.
 ##       3. Bind the data frames created for test and train set
 ##          into one large dataset by rows.

 ## Merges the train and test sets
 merged_data <- with(data_files,
                     rbind(cbind(subject_train, y_train, X_train),
                           cbind(subject_test,  y_test,  X_test)))




 ################################################################################
 # STEP 2: Extracts only the measurements on the mean and standard deviation
 #         for each measurement.
 ################################################################################

 ## Plan: 1. Find the target feature indexes which are the features
 ##          with names that contain either the string 'mean()' or 'std()',
 ##          from the data frame 'features'.
 ##       2. Add 2 to each index to adjust for the two extra column
 ##          in the beginning of the merged data frame, 'subject' and 'activity',
 ##          to create a vector with all target variables indexes.
 ##       3. Extract only the target variables from the merged data frame.

 ## Finds the target features indexes from the 'features' data frame,
 ## by searching for matches with pattens 'mean()' or 'std()'
 target_features_indexes <- grep("mean\\(\\)|std\\(\\)",
                                 data_files$features[[2]])

 ## Add 2 to each index to adjust for the first 2 column we have bind
 ## that should also be included
 target_variables_indexes <- c(1, 2, # the first two columns that refer to
                               # 'subject' and 'activity'
                               # should be included
                               # adds 2 to correct the indexes
                               # of target features indexes because of
                               # the 2 extra columns we have included
                               target_features_indexes + 2)

 ## Extracts the target variables to create the target data frame
 target_data <- merged_data[ , target_variables_indexes]




 ################################################################################
 # STEP 3: Uses descriptive activity names to name the activities in the data set
 ################################################################################

 ## Replace activity values with a factor based on levels and labels
 ## contained in the activity_labels data file.
 target_data[[2]] <- factor(target_data[[2]],
                            levels = data_files$activity_labels[[1]],
                            labels = data_files$activity_labels[[2]])




 ################################################################################
 # STEP 4: Appropriately labels the data set with descriptive variable names.
 ################################################################################

 ## Plan: 1. Extracts the target variable names from 'features',
 ##          with the use of the target features indexes created in STEP 2
 ##       2. Corrects a typo that exists in some feature names
 ##       3. Create a new tidy dataset with the appropriate labels
 ##          for the variable names

 ## Extract the target variables names
 descriptive_variable_names <- data_files$features[[2]][target_features_indexes]

 ## Correct a typo
 descriptive_variable_names <- gsub(pattern = "BodyBody", replacement = "Body",
                                    descriptive_variable_names)

 ## Create a tidy data set with appropriate labels for the variable names
 tidy_data <- target_data
 names(tidy_data) <- c("subject", "activity", descriptive_variable_names)




 ################################################################################
 # STEP 5: From the data set in step 4, creates a second, independent
 #         tidy data set with the average of each variable
 #         for each activity and each subject.
 ################################################################################

 ## Plan: 1. Group the tidy data table created in step 4,
 ##          by 'subject' and 'activity'
 ##       2. Summarize each variable to find the mean for the grouped values
 ##       3. Ungroup the data table
 ##       4. Add descriptive names to the variables of the new tidy data table
 ##       5. Write the data in a text file in the present working directory

 ## Create a dataset with the mean of each column for 'subject' and 'activity'
 tidy_data_summary <- tidy_data %>%
       group_by(subject, activity) %>%
       summarise_all(funs(mean)) %>%
       ungroup()

 ## Replace the variable names of 'tidy_data_summary' with new descriptive ones.
 ## Just the prefix "Avrg-" will be added in all variable names,
 ## except the first two, 'subject' and 'activity'.
 new_names_for_summary <- c(names(tidy_data_summary[c(1,2)]),
                            paste0("Avrg-", names(tidy_data_summary[-c(1, 2)])))
 names(tidy_data_summary) <- new_names_for_summary

 ## Save the data frame created as a text file in working directory
 write.table(tidy_data_summary, "tidy_data_summary.txt", row.names = FALSE)


 # THE END ######################################################################

